# -*- coding: utf-8 -*-
"""Queue_Search.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1frHfLKnVOv8kt-VlhQNwJ7KuWVyHtJru
"""

from time import perf_counter

# TODO: Implement path()

class SearchNode(object):
    def __init__(self, problem, state, parent=None, action=None, step_cost=0, depth=0):
        # object representing domain API, goal, heuristic
        self.problem = problem

        # Node state
        self.state = state

        # Parent node and action applied there, tree depth and children
        self.parent = parent
        self.action = action
        self.depth = depth
        self.child_list = []

        # Cost accounting
        self.step_cost = step_cost
        self.path_cost = step_cost + (0 if parent is None else parent.path_cost)
        self.path_risk = self.path_cost + problem.heuristic(state) # A*

    def is_goal(self):
        # convenience wrapper
        return self.problem.is_goal(self.state)

    def children(self):
        # return memoized children if already generated
        if len(self.child_list) > 0: return self.child_list

        # Generate children from valid actions
        domain = self.problem.domain
        for action, step_cost in domain.valid_actions(self.state):
            new_state = domain.perform_action(self.state, action)
            self.child_list.append(
                SearchNode(self.problem, new_state, self, action, step_cost, depth=self.depth+1))
        return self.child_list

    def path(self):
        node = self
        result = []
        while node.parent != None:
          result.insert(0,node.action)
          node = node.parent
        return result # Replace with implementation

if __name__ == "__main__":
  class DummyProblem:
    def __init__(self):
      self.heuristic = id

  n0 = SearchNode(problem=DummyProblem(), state=0, parent=None, action=None)
  n1 = SearchNode(problem=DummyProblem(), state=1, parent=n0, action="a1")
  n2 = SearchNode(problem=DummyProblem(), state=2, parent=n1, action="a2")
  print(n2.path()) # should be ["a1", "a2"]

# TODO: change is_goal so that all multiples of 5 are goals
# TODO: Add a default heuristic function (h_UCS) to SearchProblem

def h_ucs(state): return 0

class SearchProblem(object):
    def __init__(self, domain, initial_state, is_goal = None):
        # Default: no states are goals
        if is_goal is None: is_goal = lambda s: False

        # Domain API
        self.domain = domain

        # Initial/goal states
        self.initial_state = initial_state
        self.is_goal = is_goal

        # Heuristic for informed search
        self.heuristic = id # TODO: Replace with reasonable default
        self.heuristic = h_ucs

    def root_node(self):
        return SearchNode(self, self.initial_state)

def is_goal(s):
  return (s%2 == 0)

if __name__ == "__main__":
  problem = SearchProblem(domain=None, initial_state=0, is_goal=is_goal)
  print(problem.is_goal(5))

# TODO: change path costs in __main__ so that last node added gets popped
# TODO A*: change priority queue to use risk instead of cost

import numpy as np
from collections import deque

class FIFOFrontier(object):
    def __init__(self):
        self.queue_nodes = deque()
        self.queue_states = set()
    def push(self, node):
        if node.state not in self.queue_states:
            self.queue_nodes.append(node)
            self.queue_states.add(node.state)
    def pop(self):
        node = self.queue_nodes.popleft()
        self.queue_states.remove(node.state)
        return node
    def is_not_empty(self):
        return len(self.queue_nodes) > 0

import heapq as hq

class PriorityHeapFIFOFrontier(object):
    """
    Implementation using heapq 
    https://docs.python.org/3/library/heapq.html
    """
    def __init__(self):
        self.heap = []
        self.state_lookup = {}
        self.count = 0

    def push(self, node):
        if node.state in self.state_lookup:
            entry = self.state_lookup[node.state] # = [risk, count, node, removed]
            if entry[0] <= node.path_risk: return
            entry[-1] = True # mark removed
        new_entry = [node.path_risk, self.count, node, False]
        hq.heappush(self.heap, new_entry)
        self.state_lookup[node.state] = new_entry
        self.count += 1

    def pop(self):
        while len(self.heap) > 0:
            risk, count, node, already_removed = hq.heappop(self.heap)
            if not already_removed:
                self.state_lookup.pop(node.state)
                return node

    def is_not_empty(self):
        return len(self.heap) > 0

    def states(self):
        return list(self.state_lookup.keys())

if __name__ == "__main__":

  n0 = SearchNode(problem=DummyProblem(), state=0, parent=None, action=None)
  n1 = SearchNode(problem=DummyProblem(), state=1, parent=n0, action="a1")
  n2 = SearchNode(problem=DummyProblem(), state=2, parent=n1, action="a2")

  # TODO: change path cost so that last node added gets popped
  # n0.path_cost = 10
  # n1.path_cost = 3
  # n2.path_cost = 2
  n0.path_risk = 10
  n1.path_risk = 3
  n2.path_risk = 2

  q = PriorityHeapFIFOFrontier()
  for n in [n0, n1, n2]:
    q.push(n)
    print(q.states())
  q.pop()
  print(q.states())

def queue_search(frontier, problem):
    explored = set()
    root = problem.root_node()
    frontier.push(root)
    while frontier.is_not_empty():
        node = frontier.pop()
        if node.is_goal(): break
        explored.add(node.state)
        for child in node.children():
            if child.state in explored: continue
            frontier.push(child)
    plan = node.path() if node.is_goal() else []
    return plan

def breadth_first_search(problem):
    return queue_search(FIFOFrontier(), problem)

def uniform_cost_search(problem):
    return queue_search(PriorityHeapFIFOFrontier(), problem)

def a_star_search(problem, heuristic):
    problem.heuristic = heuristic
    return queue_search(PriorityHeapFIFOFrontier(), problem)

class BottleDomain(object):
    def __init__(self, capacities):
        self.capacities = capacities # capacities[b] is maximum capacity for the bth bottle
    def valid_actions(self, state):
        bottles = range(len(state))
        fills = [("fill %d"%b, 10*b + 1) for b in bottles if state[b] < self.capacities[b]]
        empty = [("dump %d"%b, 10*b + 1) for b in bottles if state[b] > 0]
        pours = [("pour %d into %d"%(b1,b2), 10*b1+1) for b1 in bottles for b2 in bottles if b1 != b2]
        return fills + empty + pours    
    def perform_action(self, state, action):
        new_state = list(state)
        if action[:4] == "fill":
            b = int(action[5:]) # bottle to fill
            new_state[b] = self.capacities[b]
        if action[:4] == "dump":
            b = int(action[5:]) # bottle to dump
            new_state[b] = 0
        if action[:4] == "pour":
            b1, b2 = map(int, action[5:].split(" into ")) # pour b1 into b2
            amount = min(state[b1], self.capacities[b2] - state[b2])
            new_state[b1] = state[b1] - amount
            new_state[b2] = state[b2] + amount
        return tuple(new_state)

if __name__ == "__main__":

    # Make a domain with two bottles, a 5-liter and 3-liter
    domain = BottleDomain(capacities = (5, 3))

    # Define a search problem with initial and goal states
    # is_goal is a function handle that accepts bottle states as input.
    # it returns True if the state is a goal, False otherwise.
    problem = SearchProblem(domain,
        initial_state = (0, 0),
        # is_goal = lambda s: s == (5, 3)
        # is_goal = lambda s: s[1] == 1)
        # is_goal = lambda s: s == (0, 1)
        is_goal = lambda s: (1 in s)
    )

        
    # Solve the search problem with BFS and validate the plan
    bfs_plan = breadth_first_search(problem)
    plan = uniform_cost_search(problem)
    print(bfs_plan)
    print(plan)
    state = problem.initial_state
    print(state)
    for action in plan:
        print(action)
        state = domain.perform_action(state, action)
        print(state)

# TODO: precompute cubie heuristic for speedup

"""
2x2x2 rubiks cube
state is a 2x2x2x3 char array
first 3 dimensions are positions on the cube
last dimension is the colors in each of the 3 spatial directions
spatial directions are 0:x, 1:y, 2:z
"""
import numpy as np
import matplotlib.pyplot as pt
import itertools as it
from matplotlib.patches import Polygon

R, G, B, W, Y, O = range(6)
def colorstr(i): return "RGBWYO"[i]
colors = {
    R: (1.,0.,0.), # red
    G: (0.,1.,0.), # green
    B: (0.,0.,1.), # blue
    W: (1.,1.,1.), # white
    Y: (1.,1.,0.), # yellow
    O: (1.,.64,0.), # orange
}

# convert from/to immutable type to store explored states in Python set
def unhash(state):
    return np.frombuffer(state, dtype=np.byte).reshape((2,2,2,3))
def rehash(state):
    return state.tobytes()

# solved state with same colors on each side
def solved_state():
    solved = np.zeros((2,2,2,3),dtype=np.byte)
    solved[0,:,:,0] = R
    solved[1,:,:,0] = O
    solved[:,0,:,1] = W
    solved[:,1,:,1] = Y
    solved[:,:,1,2] = G
    solved[:,:,0,2] = B
    return rehash(solved)

class RubiksDomain(object):

    def __init__(self):
        pass

    def valid_actions(self, state):
        # Action is spinning clockwise around one of the spatial axes (0, 1, or 2)
        # All step costs equal 1
        return [(0,1), (1,1), (2,1)]

    def perform_action(self, state, action):
        new_state = unhash(state).copy()
        # rotate cubie positions
        index = [slice(None)]*4
        index[action] = 1
        new_state[tuple(index)] = np.rot90(new_state[tuple(index)], axes=(0,1))
        # rotate cubies
        swap = [d for d in range(3) if d != action]
        new_state[tuple(index[:3])+(swap,)] = new_state[tuple(index[:3])+(swap[::-1],)]
        return rehash(new_state)

    def render(self, ax, state, x0, y0):
        state = unhash(state)
        angles = -np.arange(3) * np.pi * 2 / 3
        axes = np.array([np.cos(angles), np.sin(angles)])
        for d in range(3):
            for a, b in [(0,0),(0,1),(1,0),(1,1)]:
                xy = [a*axes[:,d] + b*axes[:,(d+1) % 3],
                    (a+1)*axes[:,d] + b*axes[:,(d+1) % 3],
                    (a+1)*axes[:,d] + (b+1)*axes[:,(d+1) % 3],
                    a*axes[:,d] + (b+1)*axes[:,(d+1) % 3]]
                xy = [(x+x0, y+y0) for (x,y) in xy]
                c = colors[state[tuple(np.roll((a,b,0),d))+((d+2) % 3,)]]
                ax.add_patch(Polygon(xy, facecolor=c, edgecolor='k'))

domain = RubiksDomain()
def drawcube(state, ax):
    domain.render(ax, state, 0, 0)
    ax.set_xlim([-2, 2])
    ax.set_ylim([-2, 2])
    ax.axis("equal")
    ax.axis('off')

if __name__ == "__main__":

    heuristics = {}

    def cubie_heuristic(state):
    
        solved = unhash(solved_state())
        h = [] # list of heuristics for each cubie

        state = unhash(state) # to construct masks

        # check each cubie
        for i,j,k in it.product([0,1],repeat=3):

            # Mask other cubies for lookup
            masked = 6*np.ones((2,2,2,3), dtype=np.byte) # set all other cubies to unreserved constant value
            masked[i,j,k] = state[i,j,k] # except current one
            masked = rehash(masked) # for immutable dictionary keys

            if (i,j,k) not in heuristics:
                heuristics[i,j,k] = {}

            # hasn't been solved yet
            if masked not in heuristics[i,j,k]:

                # solve mini-problem to just place that one cubie
                cubie_problem = SearchProblem(domain,
                    initial_state = masked,
                    is_goal = lambda s:
                        (unhash(s)[i,j,k] == solved[i,j,k]).all())
                cubie_plan = breadth_first_search(cubie_problem)

                # memoize for later
                heuristics[i,j,k][masked] = len(cubie_plan)
            
            h.append(heuristics[i,j,k][masked])
        return max(h)

    ### examples

    num_reps = 32
    scramble_len = 11

    solved = solved_state()
    bfs_times, as_times = [], []
    for rep in range(num_reps):

        print(f"rep {rep} of {num_reps}:")

        # scramble = [0, 1, 0, 2] # bfs
        # scramble = [2, 0, 0, 0, 1, 2, 1, 0] # decent astar example
        scramble = np.random.choice([0,1,2],(scramble_len,)) # random astar

        # print("scramble plan:")
        # print(list(plan))
        state = solved
        for a,action in enumerate(scramble):
            for _ in range(3): # one rotation in opposite orientation
                state = domain.perform_action(state, action)

        problem = SearchProblem(domain,
            initial_state = state,
            is_goal = lambda s: s == solved)

        start = perf_counter()
        bfs_plan = breadth_first_search(problem)
        duration = perf_counter()-start
        bfs_times.append(duration)
        print(f"BFS |plan| = {len(bfs_plan)}, time = {duration}s")

        start = perf_counter()
        #plan = uniform_cost_search(problem)
        as_plan = a_star_search(problem, heuristic = cubie_heuristic)
        duration = perf_counter()-start
        as_times.append(duration)
        print(f"A* |plan| = {len(as_plan)}, time = {duration}s")

    state = solved
    drawcube(state, pt.subplot(4,4,1))
    for a,action in enumerate(scramble):
        for _ in range(3): # one rotation in opposite orientation
            state = domain.perform_action(state, action)
        drawcube(state, pt.subplot(4,4,a+2))
    pt.show()

    pt.figure()
    drawcube(state, pt.subplot(4,4,1))
    for a,action in enumerate(as_plan):
        state = domain.perform_action(state, action)
        drawcube(state, pt.subplot(4,4,a+2))
    pt.show()

    pt.figure()
    pt.plot(bfs_times, label="BFS")
    pt.plot(as_times, label="A*")
    pt.xlabel("Repetition")
    pt.ylabel("Time (s)")
    pt.legend()
    pt.show()

import numpy as np
import matplotlib.pyplot as pt

WALL, CHARGER, CLEAN, DIRTY = list(range(4))
SIZE = 15

class RoombaDomain:
    def __init__(self):

        # deterministic grid world
        num_rows, num_cols = SIZE, SIZE
        grid = CLEAN*np.ones((num_rows, num_cols), dtype=int)
        grid[SIZE//2, 1:SIZE-1] = WALL
        grid[1:SIZE//2+1,SIZE//2] = WALL
        grid[0,0] = CHARGER
        grid[0,-1] = CHARGER
        grid[-1,SIZE//2] = CHARGER
        max_power = 2*SIZE
        
        self.grid = grid
        self.max_power = max_power

    def pack(self, g, r, c, p):
        return (g.tobytes(), r, c, p)
    def unpack(self, state):
        grid, r, c, p = state
        grid = np.frombuffer(grid, dtype=int).reshape(self.grid.shape).copy()
        return grid, r, c, p

    def initial_state(self):
        positions = list(zip(*np.nonzero(self.grid == CHARGER)))
        # r, c = positions[np.random.randint(len(positions))]
        r, c = 0, 0

        # Choose a subset of 5 non-wall cells to be dirty
        positions = np.random.permutation(list(zip(*np.nonzero(self.grid == CLEAN))))
        grid = self.grid.copy()
        for dirty in range(5): grid[tuple(positions[dirty])] = DIRTY

        return self.pack(grid, r, c, self.max_power)
        
    def render(self, ax, state, x=0, y=0):
        grid, r, c, p = self.unpack(state)
        num_rows, num_cols = grid.shape
        ax.imshow(grid, cmap='gray', vmin=0, vmax=3, extent=(x-.5,x+num_cols-.5, y+num_rows-.5, y-.5))
        for col in range(num_cols+1): pt.plot([x+ col-.5, x+ col-.5], [y+ -.5, y+ num_rows-.5], 'k-')
        for row in range(num_rows+1): pt.plot([x+ -.5, x+ num_cols-.5], [y+ row-.5, y+ row-.5], 'k-')
        pt.text(c-.25, r+.25, str(p), fontsize=24)
        pt.tick_params(which='both', bottom=False, left=False, labelbottom=False, labelleft=False)

    def valid_actions(self, state):
        grid, r, c, p = self.unpack(state)
        num_rows, num_cols = grid.shape
        actions = []
        if r > 0 and grid[r-1,c] != WALL: actions.append(((-1, 0), 1))
        if r < num_rows-1 and grid[r+1,c] != WALL: actions.append(((1, 0), 1))
        ### TODO: add code for column (c) boundaries
        if c > 0 and grid[r,c-1] > 0: actions.append(((0, -1), 1))
        if c < num_cols-1 and grid[r,c+1] != WALL: actions.append(((0, 1), 1))
        ### TODO: add code to deal with zero power
        if p == 0: actions = []
        return actions
    
    def perform_action(self, state, action):
        grid, r, c, p = self.unpack(state)
        dr, dc = action
        ### TODO: add code to deal with drainage and recharging
        p -= 1
        r, c = r + dr, c + dc
        if grid[r,c] == CHARGER: p = self.max_power
        ### TODO: add code to deal with cleaning
        if grid[r,c] == DIRTY: grid[r,c] = CLEAN
        new_state = self.pack(grid, r, c, p)
        return new_state

if __name__ == "__main__":

    domain = RoombaDomain()
    state = domain.initial_state()

    def is_goal(state):
        # goal: no dirty cells
        grid, r, c, p = domain.unpack(state)
        result = (grid != DIRTY).all()
        return result

    def heuristic(state):
        grid, r, c, p = domain.unpack(state)

        # get coordinate of dirty cells, if any
        dirty = list(zip(*np.nonzero(grid == 3)))
        if len(dirty) == 0: return 0

        # get distances from current roomba position to each dirty cell
        dists = [np.fabs(dr-r)+np.fabs(dc-c) for (dr, dc) in dirty]

        # an optimal plan has to travel at least the distance to the farthest one
        return max(dists)

    problem = SearchProblem(domain, domain.initial_state(), is_goal)

    start = perf_counter()
    plan = breadth_first_search(problem)
    bfs_time = perf_counter() - start
    print("bfs_time", bfs_time)

    # start = perf_counter()
    # plan, _, _ = uniform_cost_search(problem)
    # ucs_time = perf_counter() - start
    # print("ucs_time", ucs_time)

    start = perf_counter()
    plan = a_star_search(problem, heuristic)
    astar_time = perf_counter() - start
    print("astar_time", astar_time)
    print(plan)

    # state = problem.initial_state
    # pt.ion()
    # pt.figure()
    # domain.render(pt.gca(), state)
    # print(domain.valid_actions(state))
    # pt.pause(.1)
    # pt.show()
    # for action in plan:
    #     print(action)
    #     state = domain.perform_action(state, action)
    #     pt.cla()
    #     domain.render(pt.gca(), state)
    #     pt.pause(.1)

fig = pt.figure(figsize=(8,8))
state = problem.initial_state
states = [state]
for a in range(len(plan)):
  states.append(domain.perform_action(states[-1], plan[a]))

def drawframe(n):
  domain.render(pt.gca(), states[n])

from matplotlib import animation

# blit=True re-draws only the parts that have changed.
anim = animation.FuncAnimation(fig, drawframe, frames=len(states), interval=500, blit=False)

from IPython.display import HTML
HTML(anim.to_html5_video())

import numpy as np
import matplotlib.pyplot as pt

WALL, CARPET, CLEAN, DIRTY = list(range(4))

class RoombaCarpetDomain:
    def __init__(self):

        # deterministic grid world
        num_rows, num_cols = 3, 20
        grid = CLEAN*np.ones((num_rows, num_cols), dtype=int)
        grid[num_rows//2, :-1] = CARPET
        grid[0,0] = DIRTY
        
        self.grid = grid
        self.max_power = 0
        self.carpet_cost = 2*num_cols + num_rows - 6

    def pack(self, g, r, c, p):
        return (g.tobytes(), r, c, p)
    def unpack(self, state):
        grid, r, c, p = state
        grid = np.frombuffer(grid, dtype=int).reshape(self.grid.shape).copy()
        return grid, r, c, p

    def initial_state(self):
        r, c = 2, 0
        return self.pack(self.grid, r, c, self.max_power)
        
    def render(self, ax, state, x=0, y=0):
        grid, r, c, p = self.unpack(state)
        num_rows, num_cols = grid.shape
        ax.imshow(grid, cmap='gray', vmin=0, vmax=3, extent=(x-.5,x+num_cols-.5, y+num_rows-.5, y-.5))
        for col in range(num_cols+1): pt.plot([x+ col-.5, x+ col-.5], [y+ -.5, y+ num_rows-.5], 'k-')
        for row in range(num_rows+1): pt.plot([x+ -.5, x+ num_cols-.5], [y+ row-.5, y+ row-.5], 'k-')
        # pt.text(c-.25, r+.25, str(p), fontsize=24)
        pt.tick_params(which='both', bottom=False, left=False, labelbottom=False, labelleft=False)

    def valid_actions(self, state):
        grid, r, c, p = self.unpack(state)
        num_rows, num_cols = grid.shape
        actions = []

        if r > 0: actions.append(((-1, 0), self.carpet_cost if grid[r-1,c] == CARPET else 1))
        if r < num_rows-1: actions.append(((1, 0), self.carpet_cost if grid[r+1,c] == CARPET else 1))

        if c > 0: actions.append(((0, -1), self.carpet_cost if grid[r,c-1] == CARPET else 1))
        if c < num_cols-1: actions.append(((0, 1), self.carpet_cost if grid[r,c+1] == CARPET else 1))

        return actions
    
    def perform_action(self, state, action):
        grid, r, c, p = self.unpack(state)
        dr, dc = action
        r, c = r + dr, c + dc
        ### TODO: add code to deal with cleaning
        if grid[r,c] == DIRTY: grid[r,c] = CLEAN
        new_state = self.pack(grid, r, c, p)
        return new_state

if __name__ == "__main__":
    domain = RoombaCarpetDomain()
    state = domain.initial_state()

    pt.figure(figsize=(20,3))
    domain.render(pt.gca(), state)
    pt.show()

if __name__ == "__main__":

    domain = RoombaDomain()
    state = domain.initial_state()

    def is_goal(state):
        # goal: no dirty cells
        grid, r, c, p = domain.unpack(state)
        result = (grid != DIRTY).all()
        return result

    def heuristic(state):
        grid, r, c, p = domain.unpack(state)

        # get coordinate of dirty cells, if any
        dirty = list(zip(*np.nonzero(grid == 3)))
        if len(dirty) == 0: return 0

        # get distances from current roomba position to each dirty cell
        dists = [np.fabs(dr-r)+np.fabs(dc-c) for (dr, dc) in dirty]

        # an optimal plan has to travel at least the distance to the farthest one
        return max(dists)

    problem = SearchProblem(domain, domain.initial_state(), is_goal)

    start = perf_counter()
    plan = uniform_cost_search(problem)
    ucs_time = perf_counter() - start
    print("ucs_time", ucs_time)

    start = perf_counter()
    plan = a_star_search(problem, heuristic)
    astar_time = perf_counter() - start
    print("astar_time", astar_time)
    print(plan)

    # state = problem.initial_state
    # pt.ion()
    # pt.figure()
    # domain.render(pt.gca(), state)
    # print(domain.valid_actions(state))
    # pt.pause(.1)
    # pt.show()
    # for action in plan:
    #     print(action)
    #     state = domain.perform_action(state, action)
    #     pt.cla()
    #     domain.render(pt.gca(), state)
    #     pt.pause(.1)

